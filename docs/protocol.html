<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}

.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PLAY</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">home</a>
</li>
<li>
  <a href="about.html">about</a>
</li>
<li>
  <a href="people.html">people</a>
</li>
<li>
  <a href="protocol.html">protocol</a>
</li>
<li>
  <a href="data.html">data</a>
</li>
<li>
  <a href="http://github.com/PLAY-behaviorome/">code</a>
</li>
<li>
  <a href="site-info.html">site info</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="overview" class="section level1">
<h1>Overview</h1>
<p>PLAY aims to set new standards for conducting open, transparent, and reproducible behavioral science by i) publishing the protocol, and ii) making extensive use of video exemplars to demonstrate phenomena and illustrate behavioral codes. For confidentiality reasons, access to video exemplars is restricted to researchers with authorized access to <a href="http://databrary.org">Databrary</a>. To register for access, visit <a href="http://databrary.org/register" class="uri">http://databrary.org/register</a>.</p>
</div>
<div id="data-collection" class="section level1">
<h1>Data Collection</h1>
<div id="participant-inclusionexclusion-criteria" class="section level2">
<h2>Participant Inclusion/Exclusion Criteria</h2>
<p>Infants’ natural play in the home is characterized by tremendous variability including variations in: geographic location, climate, SES, maternal/paternal employment, childcare experiences, infants’ and mothers’ ages, language environment, physical layout and characteristics of the home, availability of media, toys for play, and so on. Researchers will be able to explore the effects of any/all such factors.</p>
<p>However, to ensure a sufficient sample size and based on conversations with the launch group, we will limit variability along several dimensions. To be included in the PLAY sample of 900 sessions, families must be two-parent households. All infants must be English or Spanish monolingual or bilingual. All infants must be the firstborn child and 12, 18, or 24 months of age (plus/minus one week). All infants must be full-term (37-40 weeks) without known disabilities. The mother must act as the caregiver during visits, which will be scheduled at a time when only the mother and infant are present in the home.</p>
</div>
<div id="scheduling-visit" class="section level2">
<h2>Scheduling Visit</h2>
<div id="initial-call" class="section level3">
<h3>Initial call</h3>
<p>Hi, may I speak with [MOM]?</p>
<p>My name is [CALLER NAME] and I’m calling from [LAB]. We have a study for [12 / 18 / 24]-month-olds and [CHILD] is the perfect age. Can I tell you about it?</p>
<p>What language(s) do you speak to [CHILD]?</p>
<p>→ If not ENGLISH or SPANISH: end call</p>
<p>To control for differences in communication, we are looking for families who speak mainly English or Spanish. Would it be alright if you are contacted for other studies in the future?</p>
<p>→ If yes: continue</p>
<p>For this study, we are interested in learning about babies’ natural, everyday experiences in their homes–such as the toys they play with and places they go. For this study, a researcher will visit you and [CHILD] in your home. You and [CHILD] will be video recorded for 1 hour as you go about your day. At the end of the visit we will ask questions about your family, your home, and [CHILD]’s skills and routines. We will also ask you to take us through your home as we do a video tour capturing the places [CHILD] gets to be throughout the day and things that [he/she] plays with.</p>
<p>The study will take about 2 hours. You will receive XXX for your participation. We will schedule a day and time that’s convenient for you and when [CHILD] is usually awake/alert and not during a typical meal time.</p>
<p>The data collected in this study are valuable and will be placed in a secure web-based library available only to researchers. The purpose is to share the data with experts in the field so that scientists can learn more about infant development.</p>
<p>Are you interested in participating?</p>
<p>→ If yes: Is there a day and time that works best for you (when [CHILD] is awake/alert and not a typical meal time)?</p>
<p>→ If no: Ok thank you. May we call you for other studies?</p>
<p>Voicemail</p>
<p>Hi, this message is for [MOM]. My name is [NAME] and I’m calling from [LAB]. I’m calling because we have a fun study for [12 / 18 / 24]-month-olds and [CHILD] is the perfect age. If you are interested in hearing more about the study, please give us a call back. Our phone number is [XXX-XXX-XXXX]. Thank you and we hope to hear from you soon!</p>
</div>
<div id="confirming-the-visit-2-days-before-actual-visit-email-the-day-before" class="section level3">
<h3>Confirming the visit (2 days before actual visit, email the day before)</h3>
<p>Hi, may I speak with [MOM]?</p>
<p>My name is [NAME] and I’m calling from [LAB] to confirm our visit on [DATE]. Before the visit, I’d like to ask you a few questions. It will only take 5 minutes of your time. Can we speak now?</p>
<p>→ If yes: Just as a reminder, the data we collect from you now and during the visit, will be shared on a web-based library only available to researchers like the professor who runs this lab.</p>
<p>List of questions on the Phone Questionnaire</p>
<p>Please note that presentation and format will differ in the app.</p>
<p>→ If no: Can I call you back today or tomorrow [before the visit]. Schedule call.  </p>
</div>
</div>
<div id="preparing-for-visit" class="section level2">
<h2>Preparing for Visit</h2>
<div id="pack" class="section level3">
<h3>Pack</h3>
<p>Camera, SD card and extra battery<br />
Mic Laser Measure Nesting cups (“Bruin Stacking Cups, SKU#4896742F) Shape sorter Yoga mat Tablet with app for questionnaires (if mom speaks English and/or Spanish, bring both versions of MacArthur) , study consent form, Databrary sharing release form, and decibel meter Answer choice sheet with response scales Participant payment Paper copies of all questionnaires, MCDI, and consent and Databrary forms in case of tablet failure Tools for body dimensions (Height and Weight)- TBD</p>
</div>
<div id="paperwork" class="section level3">
<h3>Paperwork</h3>
<p>Write Participant ID on all paperwork (consents and questionnaires). Fill out locomotor milestone worksheet.</p>
</div>
</div>
<div id="home-visit" class="section level2">
<h2>Home Visit</h2>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>Say to Mom:</p>
<p>“Thanks for letting us come to your home. The visit has a few parts:</p>
<p>I’ll begin by video-recording you and [CHILD] as you go about your day. I will video-record you both for 1 hour. Then, I will ask [CHILD] to play with some toys both by him/herself and with you.</p>
<p>Afterwards, I will ask you some general questions about your family and home, and about [CHILD]’s skills and routines.</p>
<p>You will give me a tour of your home that I will record on video to get a sense of the places [CHILD] goes and things that he/she plays with.</p>
<p>Do you have any questions? Let’s start with reading and signing the consent.”</p>
</div>
<div id="consent-to-participate-and-permission-to-share" class="section level3">
<h3>Consent to Participate and Permission to Share</h3>
<p>Ask parent to review form asking for consent to participate in the study. When finished, give parent a moment to look over form and sign it.</p>
<p>Ask parent to review form asking for permission to share videos and metadata. When finished, give parent a moment to look over the form and sign it. Here is the Databrary Release Language. Here are videos depicting how to ask for permission to share and a sample script.</p>
</div>
<div id="visit-protocol" class="section level3">
<h3>Visit Protocol</h3>
<div id="hour-natural-play-video-noise-measurement" class="section level4">
<h4>1: 1-Hour Natural Play Video &amp; Noise Measurement</h4>
<p>1-Hour Natural Play Video</p>
<p>Instruction to mom: “For the next hour, do anything you would typically do if I weren’t here. Try to ignore me as much as possible and I will stay out of the way. I will also try not to respond to you and [CHILD] so that he/she is not distracted. You can go anywhere in your home. You can play together or not. The idea is to capture what your typical day is like.”</p>
<p>Procedure: Keep camera on the child at all times. Specifically, ensure that the child’s whole body is visible on camera. If mom is in frame, capture as much of her body as possible without compromising view of the child. Record in front or to the side of the child as much as possible. Do not zoom in. Remain at as far a distance as possible (~3 to 5 m, hugging the wall) so that the child is not distracted by your presence. Try not to interact with the child or make eye contact with the child. Just watch through the view finder of the camera. Shoes</p>
<p>If child is wearing shoes, video-record the shoes after the session; take them off child and video the bottom, side, and top views.</p>
<p>Procedure: Zoom in with camera and comment on shoe type, heel (if any), and other observations. Decibel Meter Open the app on your tablet and start running it just before you begin recording the free play video portion of the visit.</p>
<p>Procedure: Open application (the application immediately starts recording noise levels upon startup). Place device in the most central place in the home (e.g., living room)</p>
</div>
<div id="solitary-play" class="section level4">
<h4>2: Solitary Play</h4>
<p>Interviewer: For the next few minutes, we want to see how [CHILD] plays by him/herself. We ask you not to distract him/her or tell him/her how to play. If [CHILD] tries to get your attention or wants to play with you, you can say, “Go play.” It’s perfectly fine if he/she doesn’t play with the toy. Say to child: “Here [CHILD], play with this!”</p>
<p>Camera: Record solitary toy play so that view is on baby’s body entirely and hands on object. If child moves around, follow child and keep face in frontal view. Procedure: Set yoga mat down on the floor. Un-stack cups and arrange randomly, standing upright (out of child’s view). Place child in a sitting position on yoga mat and start timing after you present the toy. Use timer on the camera (let the timer run for a bit longer than 2 min to avoid cutting the play time short. Later we code only 2 min of engagement). After 2 minutes, say: “Great job!”</p>
</div>
<div id="dyadic-mother-child-play" class="section level4">
<h4>3: Dyadic (Mother-Child) Play</h4>
<p>Interviewer: “Please sit next to [CHILD]. I’ll give you a toy. Please play with [CHILD].”</p>
<p>Procedure: Record so that the child and mother’s entire body and hands are captured. Use timer on camera to time engagement. After 3 minutes, say “Great job!”</p>
</div>
<div id="questionnaires" class="section level4">
<h4>4: Questionnaires</h4>
<p>List of Questions on 12-mo Home Questionnaire</p>
<p>List of Questions on 18-mo Home Questionnaire</p>
<p>List of Questions on 24-mo Home Questionnaire</p>
<p>Please note that presentation and format will differ in the app.</p>
<p>General Questionnaire Instructions: “I have some questions for you…” [Only give introduction to the sections that need introduction (i.e., ECBQ and MacArthur)].</p>
<p>Procedure: - Set up camera to record the questionnaires. You’ll need to change the battery on the camera to ensure sufficient power. - Sit next to the mom so she is able to read along.</p>
<p>MacArthur MacArthur should be administered in the primary language of the mom. Specific instructions and procedure are included in the questionnaire. ECBQ Read instructions on questionnaire. Give mom answer sheet with rating scale</p>
</div>
<div id="house-walkthrough-room-measurements" class="section level4">
<h4>5: House Walkthrough &amp; Room Measurements</h4>
<p>Video House Walkthrough</p>
<p>Instructions: “Now, we would like to see the space that [CHILD] gets to explore throughout the day. Please give me a tour of your home as I follow with a camera, and take measurements of the spaces. As we walk around, please mention the things that [CHILD] plays with in each room. Please show me where you keep his/her clothes to give us an idea of the kinds of things he/she wears.”</p>
<p>Procedure (Video): Pause at the entrance of the room. Name the room by its function (e.g., “This is where [CHILD] sleeps”). First, pan the camera SLOWLY from Left to Right. Then, pan the camera to Floor, name the different types of surfaces in the space (hardwood, plush carpet, thin rug, linoleum, tile, etc.), and then pan to the Ceiling. Hold the camera in one hand while you take measurements of the room. Do NOT turn off the camera when walking to next room. Walk SLOWLY. Room Measurements with Laser Distance Measurer Measure all rooms in the house. Room = any space used by someone on a regular basis, including: bedrooms, kitchens, bathrooms, and basements. Do not measure laundry rooms. Rooms don’t have to have windows. A room has to have a clear demarcation (e.g., a wall or an entry). If the room has a short divider (e.g., when a kitchen and a living room are divided by a counter), count as one big room and measure accordingly.</p>
<p>Procedure: Turn measure on by pressing ON/DIST button. Make sure the laser is on. Place the base of the laser flat on the wall. Avoid moldings and door castings. Measure wall to wall, lengthwise and widthwise. If a room has an odd or asymmetrical shape (i.e., any shape other than a rectangle or a square), measure the largest rectangle or square area of the room. Press ON/DIST again to take measurement. Repeat the above for length and width. Focus camera on laser measure and read measurements out loud.</p>
</div>
<div id="body-dimensions" class="section level4">
<h4>6: Body Dimensions</h4>
<p>[TBD]</p>
</div>
<div id="visit-wrap-up" class="section level4">
<h4>7: Visit Wrap-up</h4>
<p>Complete home measurement, housing checklist sections of the Home Questionnaire. Upload videos, questionnaires, and house decibel data to Databrary. When you arrive back at the lab, wash all toys and equipment thoroughly. Wipe down yoga mat. Rinse nesting cups in bleach-water. Do not submerge shape sorter in water (or it will stop making noise).</p>
</div>
</div>
</div>
</div>
<div id="coding-set-up" class="section level1">
<h1>Coding Set Up</h1>
<p>This section describes how to transcribing &amp; code the 1-hour natural play session.</p>
<div id="getting-started" class="section level2">
<h2>Getting Started</h2>
<p>Download the <a href="http://datavyu.org/download.html">development version of Datavyu</a>. Download the <code>PLAY_CodingTemplate.opf</code> file from the <a href="https://nyu.databrary.org/volume/254/slot/14924/-?asset=73892">PLAY Databrary Volume</a>. Name this file with the PLAY naming convention (e.g., PLAY_NYU001, … PLAY_NYU010, … PLAY_NYU030). - This template contains all of the primary variables that will be coded by each site: communication, gesture, object interaction, locomotion, and emotion. Download Ruby scripts for each coding variable as needed from the <a href="https://github.com/databrary/PLAY-Project-Datavyu-scripts">PLAY Github repository</a>.</p>
</div>
<div id="get-to-know-datavyu" class="section level2">
<h2>Get to Know Datavyu</h2>
<p>Familiarize yourself with Datavyu before you begin coding (resources on Datavyu.org, videos from past workshops, etc.). Refer to the <a href="http://www.datavyu.org/user-guide/index.html">Datavyu User Guide</a>. Take a look at our <a href="http://www.datavyu.org/user-guide/best-practices.html">Best Practices for Coding Behavioral Data From Video</a> on the Datavyu site.</p>
</div>
<div id="coding-in-passes" class="section level2">
<h2>Coding in Passes</h2>
<p>The coding manual describes the transcription process and codes for 5 content areas: communication, gesture, object interaction, locomotion, and emotion. Each content area includes two passes: one pass for the infant and one pass for the mother. For gesture, the baby and mom are coded together in a single pass. A pass entails scoring the relevant codes for 1-hour of video.</p>
<pre><code>Please visit our [GitHub Repository](https://github.com/databrary/PLAY-Project-Datavyu-scripts) for all of the scripts mentioned in this wiki.</code></pre>
</div>
<div id="workflow-for-coding-communication-passes" class="section level2">
<h2>Workflow for Coding Communication Passes</h2>
<p>After the file has been transcribed according to procedure in Transcription, run two additional scripts that will prepare new Communication columns for further coding. Run <code>splitmombaby_transcribe.rb</code>. This script pulls out mom and baby language from the transcribe column into two new columns: (1) momspeech and (2) babyvoc. Each column is automatically populated with cells from the respectively tagged utterances from the transcribe column (e.g., the script ports all utterances coded as ‘m’ to the momspeech column and ‘b’ to the babyvoc column). Each new cell in momspeech and babyvoc is a point cell created at the onset of each cell from the transcription. Run create_mombaby_utterancetype.rb. This script also creates two new columns: (1) momutterancetype and (2) babyutterancetype. For each cell in momspeech and babyvoc, a new cell is created in momutterancetype and babyutterancetype, respectively. The codes for these cells are blank, and the coder now scores mom and baby communication according to definitions in Communication Codes.</p>
</div>
<div id="workflow-for-coding-gesture-pass" class="section level2">
<h2>Workflow for Coding Gesture Pass</h2>
<p>Score baby and mom gesture together in a single pass according to definitions in Gesture Codes. After the gesture coding pass (for both mom and baby) has been done, run a script that will separate mom and baby gestures into two columns. Run Split-MomBabyGesture.rb. This script pulls out mom and baby gestures from the gesture column into two new columns: (1) babygesture and (2) momgesture. Each column is automatically populated with cells from the respectively tagged events from the gesture column (e.g., the script ports all gestures coded as ‘m’ to the momgesture column and ‘b’ to the babygesture column). Each new cell in babygesture and momgesture is a point cell created at the onset of each cell in the gesture column.</p>
</div>
<div id="workflow-for-object-locomotion-and-emotion-passes" class="section level2">
<h2>Workflow for Object, Locomotion, and Emotion Passes</h2>
<p>Choose whether to code baby or mom first within each pass for object, locomotion, or emotion. Score each pass according to definitions in Object Codes, Locomotion Codes, or Emotion Codes. Workflow for Inter-Observer Reliability on Communication, Gesture, Object, Locomotion, and Emotion Passes After the primary coder finishes a pass: babyutterancetype, momutterancetype, gesture (split into babygesture, momgesture), babyobject, momobject, babyloc, momloc, babyemotion, or momemotion run two scripts to set up the Datavyu spreadsheet for coding reliability. First, run a script called insert-RelBlocks.rb. This script randomly generates 3, 5-minute chunks within the first, second, and third 20-minute sections of the 1-hour video of free play. By quasi-randomly inserting reliability blocks from areas of the primary coder’s pass, this will ensure that the reliability coder sees each portion of the video for each child’s session. Thus, the idiosyncrasies of each child, fluctuations over the 1-hour session, and drift in the coder are spread over the session. Reliability on each coding pass is done on the same 3, 5-minute blocks for each pass. The scripting window in Datavyu will prompt when everything has been successfully completed. You should now have a brand new column in your spreadsheet named reliability_blocks. This script should only be run once so that reliability coding can be done within the same time frame for each coding domain for each session. Now, run another script appropriate for the pass reliability needs to be coded on: CreateReliability-BabyUtterancetype.rb or CreateReliability-MomUtterancetype.rb or CreateReliability-Gesture.rb or CreateReliability-MomBaby-Loc.rb or CreateReliability-MomBaby-Object.rb OR CreateReliability-MomBaby-Emotion.rb This script inserts new coding columns where your reliability coder will score the video while they are locked into the script-generated, 5-minute chunks in the reliability_blocks column.</p>
</div>
</div>
<div id="coding-id" class="section level1">
<h1>Coding ID</h1>
<p>Datavyu ID Code for 1-Hour Natural Play</p>
<pre><code>Make sure you are currently logged in at Databrary to view embedded video examples in this wiki.</code></pre>
<div id="id" class="section level2">
<h2>id</h2>
<p><code>&lt;site&gt;</code> <code>&lt;participant&gt;</code> <code>&lt;testdate&gt;</code> <code>&lt;birthdate&gt;</code> <code>&lt;agegroup&gt;</code> <code>&lt;sex&gt;</code> <code>&lt;study&gt;</code> <code>&lt;babylanguage1&gt;</code> <code>&lt;babylanguage2&gt;</code> <code>&lt;momlanguage2&gt;</code> <code>&lt;momlanguage2&gt;</code></p>
<div id="operational-definitions" class="section level3">
<h3>Operational Definitions</h3>
<p><code>&lt;onset/offset&gt;</code> Set every ID cell onset to 00:00:00:000 (hours : minutes : seconds : milliseconds).</p>
<p>Set ID cell offset to the last frame in the 1-hour free play session.</p>
<p><code>&lt;site&gt;</code> Site refers to the data collection site: New York University, Rutgers Newark, CUNY Staten Island, Penn State, etc.</p>
<p>Get the site from the metadata information collected on the app.</p>
<p>Format is three letters all caps: NYU, RTG, CSI, PSU.</p>
<p><code>&lt;participant&gt;</code> Participant number refers to the infant’s participant number in the order that the data were collected.</p>
<p>Participant numbers run consecutively from 001 within each site.</p>
<p>Get the participant number from the metadata information collected on the app.</p>
<p>Format for id number is three digits 001, 012, 021.</p>
<p><code>&lt;testdate&gt;</code> Test date is the day of the home visit.</p>
<p>Get the test date from the metadata information collected on the app.</p>
<p>Format for test date is YYYY-MM-DD.</p>
<p><code>&lt;birthdate&gt;</code> Birth date is the day the baby was born.</p>
<p>Get the birth date from the metadata information collected on the app.</p>
<p>Format for birth date is YYYY-MM-DD.</p>
<p><code>&lt;agegroup&gt;</code> Entered as 12, 18, or 24.</p>
<p>Get the age group from the metadata information collected on the app.</p>
<p><code>&lt;sex&gt;</code> Refers to infant’s biological sex.</p>
<p>Code ‘m’ = male/boy; ‘f’ = female/girl.</p>
<p>Get the sex from the metadata information collected on the app.</p>
<p><code>&lt;study&gt;</code> Study name.</p>
<p>Code as ‘PLAY’.</p>
<p><code>&lt;babylanguage1&gt;</code> Refers to infant’s predominant language spoken during the session.</p>
<p>Code with lowercase, full name of the language: ‘english’ or ‘spanish’.</p>
<p><code>&lt;babylanguage2&gt;</code> Refers to infant’s other language spoken during the session, if another language was spoken.</p>
<p>Code with lowercase, full name of the language: ‘english’ or ‘spanish’. If no other language was spoken as missing ‘.’</p>
<p><code>&lt;momlanguage1&gt;</code> Refers to mother’s predominant language spoken during the session.</p>
<p>Code with lowercase, full name of the language: ‘english’ or ‘spanish’.</p>
<p><code>&lt;momlanguage2&gt;</code> Refers to mother’s other language spoken during the session, if another language was spoken.</p>
<p>Code with lowercase, full name of the language: ‘english’ or ‘spanish’. If no other language was spoken as missing ‘.’</p>
</div>
</div>
</div>
<div id="transcription" class="section level1">
<h1>Transcription</h1>
<p>The 1-hour natural activity segment will be completely transcribed.</p>
<div id="transcribe" class="section level2">
<h2>transcribe</h2>
<p><code>&lt;source_m-b&gt;</code> <code>&lt;content&gt;</code></p>
</div>
<div id="general-orientation" class="section level2">
<h2>General Orientation</h2>
<p>The transcribe column is used to tag the onset of each utterance/vocalization by the mom and baby in a single pass. Then based on the <code>&lt;source&gt;</code> of the utterance/vocalization, the momspeech and babyvoc columns are automatically populated by a script.</p>
<p>Utterance = a unit of speech separated by silence/pause, which can be a natural “period” as in end of a complete thought or sentence or a long pause (i.e., taking a breath). Utterances are coded as events (cells) separated by gray where no utterances are spoken. These are coded as events, where there is only one time that is tagged (onset), which is any time during the utterance. We do not code strict onsets and offset for the event; a single time during the utterance is the time coded.</p>
<p>Transcribe all of mothers’ utterances even if they are not baby-directed. But only transcribe communicative utterances; that is, there is no need to tag and transcribe non-speech, non-communicative sounds by the mother (e.g., making whistling noises, muttering to herself indistinguishably).</p>
<p>Paralinguistic utterances/vocalizations (e.g., laughing, crying, sighing, screaming) by the mom should be typed out (e.g., “ah”). Non-linguistic vocalizations by the baby are coded as “c” (a catch all for crying, laughing, screaming, grunting). Linguistic babbling, vowels, consonants, and combinations of the above by the baby that are not words are coded as “b”.</p>
</div>
<div id="value-list" class="section level2">
<h2>Value List</h2>
<p><code>&lt;source_m-b&gt;</code></p>
<p>m = mom</p>
<p>b = baby</p>
<p><code>&lt;content&gt;</code></p>
<p>If the content of the utterance can be heard clearly by the coder, then type transcript of each utterance in the cell.</p>
<p>b = babbling, or vowel/consonant sound by the baby</p>
<p>c = crying, screaming, grunting, laughing sound by the baby</p>
<div id="operational-definitions-1" class="section level3">
<h3>Operational Definitions</h3>
<p><code>&lt;source_m-b&gt;</code> <code>&lt;m&gt;</code> Code ‘m’ if the mom is the source of the utterance. This code will be filled in automatically using quick keys.</p>
<p><code>&lt;b&gt;</code></p>
<p>Code ‘b’ if the baby is the source of the utterance. This code will be filled in automatically using quick keys.</p>
<p><code>&lt;content&gt;</code> transcribe utterance Type the complete utterance. Type everything in lower case, except for proper names (e.g., Mommy, I, Cheerios, Anna). Use apostrophes correctly for contractions and possessives (e.g., don’t, where’s, Daddy’s, Lily’s). Do not use “,” commas.</p>
<p>Transcription: “snowmans dont drink coffee” </br> <video width="320" height="240" controls> <source src="https://nyu.databrary.org/slot/14765/-/asset/63400/download?inline=true" type="video/mp4"> Your browser does not support the video tag. </video> </br> <a href="https://nyu.databrary.org/slot/14765/-/asset/63400/download?inline=true" class="uri">https://nyu.databrary.org/slot/14765/-/asset/63400/download?inline=true</a> </br></p>
<p>Transcription: “un caballo” </br> <video width="320" height="240" controls> <source src="https://nyu.databrary.org/slot/14765/-/asset/63406/download?inline=true" type="video/mp4"> Your browser does not support the video tag. </video> </br> <a href="https://nyu.databrary.org/slot/14765/-/asset/63406/download?inline=true" class="uri">https://nyu.databrary.org/slot/14765/-/asset/63406/download?inline=true</a> </br></p>
<p>Transcription: “momma” </br> <video width="320" height="240" controls> <source src="https://nyu.databrary.org/slot/14765/-/asset/63404/download?inline=true" type="video/mp4"> Your browser does not support the video tag. </video> </br> <a href="https://nyu.databrary.org/slot/14765/-/asset/63404/download?inline=true" class="uri">https://nyu.databrary.org/slot/14765/-/asset/63404/download?inline=true</a> </br></p>
<p>Transcription: “woof woof” </br> <video width="320" height="240" controls> <source src="https://nyu.databrary.org/slot/14765/-/asset/63414/download?inline=true" type="video/mp4"> Your browser does not support the video tag. </video> </br> <a href="https://nyu.databrary.org/slot/14765/-/asset/63414/download?inline=true" class="uri">https://nyu.databrary.org/slot/14765/-/asset/63414/download?inline=true</a> </br></p>
<p>Put a question mark “?” at the end of any utterance that is a question.</p>
<p>Transcription: “want cheerios?” </br> <video width="320" height="240" controls> <source src="https://nyu.databrary.org/slot/14765/-/asset/63408/download?inline=true" type="video/mp4"> Your browser does not support the video tag. </video> </br> <a href="https://nyu.databrary.org/slot/14765/-/asset/63408/download?inline=true" class="uri">https://nyu.databrary.org/slot/14765/-/asset/63408/download?inline=true</a> </br></p>
<p>Individual letters (e.g., mom spells out zoo as “z” “o” “o”) need to be marked with an @ (at symbol) so that they’re not confused with actual words, for example z@ o@ o@. Use existing rules for utterances to decide if each letter is it’s own utterance.</p>
<p>Any utterance that is unintelligible or hard to decipher, code as “xxx”. This could be the full utterance: for example, the mom says multiple words but they are all unintelligible, so the entire code is “xxx”. Or part of the utterance is intelligible, but part is not: for example, the mom says “give me” and what she says to give is unintelligible, so code “give me xxx”.</p>
<p>Transcription: “xxx” </br> <video width="320" height="240" controls> <source src="https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true" type="video/mp4"> Your browser does not support the video tag. </video> </br> <a href="https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true" class="uri">https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true</a></p>
<p>In case of language-functioning sounds by the mom or baby, these are typed out as words phonetically as specified below: Ahem (ready to speak), Ay (surprise), Huhuh (no), Hmm (thinking or questioning), Mmhm (yes), Sh (shush), Uhhuh (yes), Uhoh (blunder), uhuh (no), Yeah (yes), Whee (excitement), Whoah (surprise), Whoops (mistake)</p>
<p>If you encounter a mouth sound that the mom makes, which is communicative but cannot be transcribed phonetically (e.g., lip sucking/kissing sound to call the baby over), write out the sound of the vocalization in brackets (e.g. [lip sucking/kissing]). Only write out communicative sounds: for instance, if the mom whistles to get the baby’s attention write out [whistles], but if the mom is just whistling to herself as she cooks then do not tag as an utterance.</p>
<p><code>&lt;b&gt;</code> Code ‘b’ if the baby is not saying a full language phrase or sentence. Could be babbling, by saying one or more consonant-vowel pairs. Or could be just a vowel. If you are unsure if it was a language phrase that you can transcribe or was just a babble, then mark as unintelligible “xxx” and make a comment. Either relisten or come back after getting more context later in the video.</p>
<p><code>&lt;c&gt;</code> Code ‘c’ if the baby is making a non-language-like vocalization. For instance, crying, screaming, laughing, grunting. Any vocalization that is not a consonant-vowel babble or vowel alone. These should be easy to distinguish from babbling, because they serve a different communicative function.</p>
</div>
</div>
<div id="how-to-transcribe" class="section level2">
<h2>How to Transcribe</h2>
<p>Set “Jump back by” on the Controller to 2 seconds.</p>
<p>Transcribing is done in two iterative passes through a small section of the video (roughly 1-2 minutes). The first part is tagging utterances for about 1-2 minutes (until a good break in activity is reached) and the second part is looping back over that same portion of the video to transcribe utterances.</p>
<div id="tagging-utterances" class="section level3">
<h3>Tagging Utterances</h3>
<p>Turn on Quick Keys mode by hitting Shift-Cmnd-K (or selecting Spreadsheet&gt;Enable Quick Keys from the menu bar). You will see <code>&lt;QUICK KEY MODE&gt;</code> in the spreadsheet window header. This will enable a function that every time an alphanumeric key is pressed, a new point cell (onset=offset) is inserted at the current time in the data controller, and the alphanumeric key pressed will be inserted as the code of the first argument.</p>
<p>Place your left index finger on the “m” key and your left ring finger on the “b” key. The right fingers should be on pause and shuttle forward and back. Play the video at 1/2 speed (or 1/4 speed if a fast exchange of utterances is happening). Press the “m” or “b” key every time the mom or baby has an utterance, while you play the video back. Insert cells as soon as you hear something. Be as alert and attentive as possible.</p>
<p>If you think you hear an utterance, tag it. It’s much better to be fast and insert extra cells, rather than judge yourself and have to go back later to fix the time or insert a cell for an utterance you missed. You can easily delete cells using shortcut keys. You can also fix the <code>&lt;source&gt;</code> code later if you hit the wrong key. Note, offsets are not coded. Onsets are as close to the utterance onset as you possibly can get. So optimize your attention and coding for speed of tagging.</p>
<p>The best strategy is to have an unbroken playback session of 1-2 mins where you are just tagging utterances without stopping. Stop playback once you’ve tagged 30-40 cells, 1-2 mins have elapsed, or you hit a good breaking point in an activity (e.g. baby moves onto playing with a new toy). Try to stop a tagging utterances past as soon as you tag a new utterance, rather than playing further into silence of the video; that way you can jump to and pick up right where you left off at an utterance for the next tagging pass, instead of potentially re-playing the same part of the video.</p>
<p>Now, turn off Quick Keys (Shift-Cmnd-K). Run the addtime_transcribe.rb script. This will add 500 ms to the offset, which will help in highlighting in the next step.</p>
</div>
<div id="transcribe-utterances" class="section level3">
<h3>Transcribe Utterances</h3>
<p>Turn on Highlight and Focus Mode by hitting Shift-Cmnd-F (or selecting Spreadsheet&gt;Enable Highlight and Focus Mode from the menu bar). This will highlight each cell as you loop back through the 1-2 mins you just tagged utterances in and put the focus of data entry (cursor) into the first uncoded argument in that cell (which will be <code>&lt;content&gt;</code>).</p>
<p>SCROLL or ARROW up to the first cell from the most recent utterance tagging done. Jump to that first cell (+ key) and then JUMP-BACK-BY 2 s (- key). Playback the video at 1x speed. Listen to each utterance within the context of the ongoing stream of speech. JUMP-BACK and re-listen as many times as needed until you are sure of the utterance. Once you are sure of the utterance, stop playback and transcribe the utterance or insert the appropriate code (for the baby).</p>
<p>If you go past an utterance and missed transcribing it, hit the jump back key until you are right before it. If you get lost in the transcription, JUMP BACK 2-3 cells (by arrowing or jump back key) before where you lost track of transcribing. It’s much better to use the keyboard to navigate and loop back (jump back or arrow up or down) rather than mousing. (Note: you may need to mouse into the argument of the first cell in a section after tagging utterances). If you mouse and jump around, you will get lost; stay in “looping” mode throughout transcription even if it means listening multiple times to a single section.</p>
<p>If you find a cell for an utterance that was tagged by mistake (you thought there was an utterance but there wasn’t) then delete that cell. JUMP-BACK-BY 2 s before the cell you deleted and confirm there was no utterance and that the next utterance is tagged at the correct time. (Note: you may need to mouse into a cell after deleting).</p>
<p>If you need to change the onset of an utterance, ARROW into it (or let auto focus move you into it) and hit the 7 key to set onset to the current time. Do not worry about setting or fixing the offset.</p>
<p>If you missed tagging an utterance in the first part, find the time of the utterance onset while you are transcribing. Hit ENTER and set the offset (same time as onset) using the 9 key. Code “m” or “b” for <code>&lt;source&gt;</code>, then tab into <code>&lt;content&gt;</code> and transcribe.</p>
<p>Turn off Highlight and Focus Mode. Save the file. Now turn back on Quick Keys, jump to the onset of the last cell transcribed, and revert back to the coding strategy for tagging utterances.</p>
</div>
<div id="splitting-mom-and-baby-utterances" class="section level3">
<h3>Splitting Mom and Baby Utterances</h3>
<p>It’s easier and faster to tag and transcribe mom and baby together in one pass. But for later coding, we want mom speech and baby vocalizations to be in two separate columns.</p>
<p>Run the <code>splitmombabytranscribe.rb</code> script to pull mom and baby utterances into their appropriate columns.</p>
<p>At this step, you can also run the <code>createmombabyutterancetype.rb</code> script to insert the momutterancetype and babyutterancetype columns and insert cells for every tagged utterance.</p>
</div>
</div>
</div>

<p>Copyright &copy; 2018- Karen E. Adolph, Catherine Tamis-LeMonda, & Rick O. Gilmore</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
